---
title: "hw5"
author: "Klimenko Sveta"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(irr)
```

### 1.1
Скачайте датасет hw1_1_zilo_class.csv. Получите тиббл содержащий два столбца: stimulus_source и количество уникальных слов в датасете (n).

```{r}
data_zilo <- read_csv("https://raw.githubusercontent.com/agricolamz/2018_data_analysis_for_linguists/master/data/students/s-klimenko/hw2_agreement/hw2_1_zilo_class.csv")
data_zilo <- as_tibble(data_zilo)
data_zilo %>%
  distinct(stimulus_source, stimulus)  %>% 
  count(stimulus_source)
```

### 1.2
Преобразуйте датасет hw1_1_zilo_class.csv. Посчитайте процент полного согласия всех спикеров.

```{r}
data_zilo %>% 
  select(s_id, stimulus, translation_ru, stimulus_source, class) %>% 
  spread(key = s_id, value = class) ->
  zilo_classes_short
head(zilo_classes_short)

agree(zilo_classes_short[,-c(1:3)])
```

### 1.3
Из преобразованным датасета hw1_1_zilo_class.csv выберите спикеров с номером 7 и 11 и посчитайте для них каппу Коэна.

```{r}
zilo_classes_2s <- zilo_classes_short[,c(7, 11)]
kappa2(zilo_classes_2s)
```

### 1.4
Посчитайте каппу Фляйса для всех спикеров преобразованного датасета hw1_1_zilo_class.csv.

```{r}
kappam.fleiss(zilo_classes_short[,-c(1:3)])
```

### 1.5
Представим, что Вы пишите статью, напишите короткий абзац, который бы обобщал результаты, полученные в предыдущих заданиях.

Были обработаны данные эксперимента, в котором носителям зиловского диалекта андийского языка требовалось отнести 89 слов к классу заимствованной или исконной лексики. 
Процент полного согласия спикеров - 73%.
Поскольку при использовании этого метода не учитываются случайные совпадения, мы не можем в должной мере интерпретировать результаты и должны использовать другие методы.
Каппа Коэна - 0.75. Результаты находятся в интервале 0.61–0.80, что следует интерпретировать как значительное согласие.
Каппа Фляйса - 0.84. Результаты находятся в интервале 0.81–0.90, что следует интерпретировать как почти идеальное согласие.

### 2.1
Скачайте датасет hw1_2_verbs.csv (см. описание выше). Посчитайте количество участников в датасете (в ответ выведите тибл с переменной n).

```{r}
data_v <- read_csv("https://raw.githubusercontent.com/agricolamz/2018_data_analysis_for_linguists/master/data/students/s-klimenko/hw2_agreement/hw2_2_verbs.csv")
data_v <- as_tibble(data_v)
data_v %>%
  distinct(SubjectCode) %>% 
  count()
```

### 2.2
Посчитайте среднюю оценку глаголов разного типа для каждого пола в датасете (в ответ выведите тибл с переменными  WordType, Gender и mean).

```{r}
data_v %>%
  group_by(WordType, Gender) %>% 
  summarise(mean = mean(GivenScore))
```

### 2.3
Преобразуйте датасет в короткий формат и удалите строки, в которых есть пропущенные значения (у меня вышел тибл 59 x 124). Посчитайте процент полного согласия.

```{r}
data_v %>% 
  select(SubjectCode, Stimulus, GivenScore) %>% 
  spread(key = SubjectCode, value = GivenScore) ->
  data_short
data_short <- drop_na(data_short)
agree(data_short[,-c(1:3)])
```

### 2.4
Посчитайте каппу Фляйса для преобразованного датасета.

```{r}
kappam.fleiss(data_short[,-c(1:3)])
```

### 2.5
Посчитайте ICC для преобразованного датасета.

```{r}
icc(data_short[,-c(1:3)], model = "twoway", type = "agreement")
```

### 2.6
Создайте тибл, содержащий минимальное (min) и максимальное (max) значение попарной корреляции Кендала ответов всех участников эксперимента со словами (т. е. корреляция ответов АА и AB, AA и AC и т. д.). В преобразовании матрицы, пораждаемой функцией cor() мне очень помогла функция as.table().

```{r}
kendall <- as.table(cor(data_short[, -c(1:3)], method = "kendall"))
tibble(min_kendall = min(kendall[lower.tri(kendall)]), max_kendall = max(kendall[lower.tri(kendall)]))
```
